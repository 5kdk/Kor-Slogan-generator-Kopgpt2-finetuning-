{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 변수 선언\r\n",
    "\r\n",
    "MODEL_NAME = 'distilgpt2' #'distilgpt2' 'gpt2-medium'\r\n",
    "DATA_IN_PATH = \"./datasets/\"\r\n",
    "DATA_OUT_PATH = \"./models/\"\r\n",
    "TRAIN_DATA_FILE = \"slogans.csv\"\r\n",
    "TRAIN_DATA_NAME = \"en slogan\"\r\n",
    "PLOT_OUT_PATH = \"./plots/\"\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\r\n",
    "\r\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\r\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Declare special tokens for padding and separating the context from the slogan:\r\n",
    "SPECIAL_TOKENS_DICT = {\r\n",
    "    'pad_token': '<pad>',\r\n",
    "    'additional_special_tokens': ['<context>', '<slogan>'],\r\n",
    "}\r\n",
    "\r\n",
    "# 어휘에 다음 특수 토큰을 추가하고 모델의 임베딩 크기를 조정:\r\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS_DICT)\r\n",
    "model.resize_token_embeddings(len(tokenizer))\r\n",
    "\r\n",
    "print(tokenizer.special_tokens_map)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<context>', '<slogan>']\"}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import csv\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import Dataset\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "class SloganDataset(Dataset):\r\n",
    "  def __init__(self, filename, tokenizer, seq_length=64):\r\n",
    "\r\n",
    "    context_tkn = tokenizer.additional_special_tokens_ids[0]\r\n",
    "    slogan_tkn = tokenizer.additional_special_tokens_ids[1]\r\n",
    "    pad_tkn = tokenizer.pad_token_id\r\n",
    "    eos_tkn = tokenizer.eos_token_id\r\n",
    "\r\n",
    "    self.examples = []\r\n",
    "    with open(filename, 'r', encoding='UTF-8') as csvfile:\r\n",
    "      reader = csv.reader(csvfile)\r\n",
    "      for row in reader:\r\n",
    "      \r\n",
    "        context = [context_tkn] + tokenizer.encode(row[0], max_length=seq_length//2-1)\r\n",
    "        slogan = [slogan_tkn] + tokenizer.encode(row[1], max_length=seq_length//2-2) + [eos_tkn]\r\n",
    "        \r\n",
    "        \r\n",
    "        tokens = context + slogan + [pad_tkn] * ( seq_length - len(context) - len(slogan) )\r\n",
    "\r\n",
    "        segments = [context_tkn] * len(context) + [slogan_tkn] * ( seq_length - len(context) )\r\n",
    "\r\n",
    "        labels = [-100] * (len(context)+1) + slogan[1:] + [-100] * ( seq_length - len(context) - len(slogan) )\r\n",
    "\r\n",
    "        self.examples.append((tokens, segments, labels))\r\n",
    "\r\n",
    "  def __len__(self):\r\n",
    "    return len(self.examples)\r\n",
    "\r\n",
    "  def __getitem__(self, item):\r\n",
    "    return torch.tensor(self.examples[item])\r\n",
    "\r\n",
    "slogan_dataset = SloganDataset(DATA_IN_PATH + TRAIN_DATA_FILE, tokenizer)\r\n",
    "print(next(iter(slogan_dataset)).size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import math, random\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
    "\r\n",
    "indices = list(range(len(slogan_dataset)))\r\n",
    "\r\n",
    "random.seed(100)\r\n",
    "random.shuffle(indices)\r\n",
    "\r\n",
    "split = math.floor(0.1 * len(slogan_dataset))\r\n",
    "train_indices, val_indices = indices[split:], indices[:split]\r\n",
    "\r\n",
    "train_sampler = SubsetRandomSampler(train_indices)\r\n",
    "val_sampler = SubsetRandomSampler(val_indices)\r\n",
    "\r\n",
    "train_loader = DataLoader(slogan_dataset, batch_size=32, sampler=train_sampler)\r\n",
    "val_loader = DataLoader(slogan_dataset, batch_size=64, sampler=val_sampler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "import os\r\n",
    "\r\n",
    "\r\n",
    "def fit(model, optimizer, train_dl, val_dl, epochs=1, device=torch.device('cpu')):\r\n",
    "  \r\n",
    "  if not os.path.exists(DATA_OUT_PATH):\r\n",
    "    os.makedirs(DATA_OUT_PATH)\r\n",
    "    print('--- Directory creation completed successfully ---')\r\n",
    "  else:\r\n",
    "    print('--- Directory already exists ---')\r\n",
    "  \r\n",
    "\r\n",
    "  for i in range(epochs):\r\n",
    "\r\n",
    "    print('\\n--- Starting epoch #{} ---'.format(i+1))\r\n",
    "\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    losses = []\r\n",
    "    nums = []\r\n",
    "\r\n",
    "    for xb in tqdm(train_dl, desc=\"Training\"):\r\n",
    "\r\n",
    "      inputs = xb.to(device)\r\n",
    "\r\n",
    "      outputs = model(inputs[:,0,:], token_type_ids=inputs[:,1,:], labels=inputs[:,2,:])\r\n",
    "      \r\n",
    "      loss = outputs[0]\r\n",
    "      losses.append(loss.item())\r\n",
    "      nums.append(len(xb))\r\n",
    "\r\n",
    "      loss.backward()\r\n",
    "\r\n",
    "      optimizer.step()\r\n",
    "      model.zero_grad()\r\n",
    "\r\n",
    "    train_cost = np.sum(np.multiply(losses, nums)) / sum(nums)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    with torch.no_grad():\r\n",
    "      losses = []\r\n",
    "      nums = []\r\n",
    "\r\n",
    "      for xb in tqdm(val_dl, desc=\"Validation\"):\r\n",
    "        inputs = xb.to(device)\r\n",
    "        outputs = model(inputs[:,0,:], token_type_ids=inputs[:,1,:], labels=inputs[:,2,:])\r\n",
    "        losses.append(outputs[0].item())\r\n",
    "        nums.append(len(xb))\r\n",
    "\r\n",
    "    val_cost = np.sum(np.multiply(losses, nums)) / sum(nums)\r\n",
    "    \r\n",
    "    print('\\n--- Epoch #{} finished --- Training cost: {} / Validation cost: {}'.format(i+1, train_cost, val_cost))\r\n",
    "\r\n",
    "    if (i + 1) % 1 == 0 :\r\n",
    "      torch.save(model.state_dict(), DATA_OUT_PATH + TRAIN_DATA_NAME + '_' + f'{i+1}epoch' + '_' + 'model.pth')\r\n",
    "      print(f'\\n--- Epoch #{i+1} Saving complete ! ---')\r\n",
    "  \r\n",
    "    torch.cuda.empty_cache()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from transformers import AdamW\r\n",
    "\r\n",
    "# Move the model to the GPU:\r\n",
    "device = torch.device('cuda')\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "# Fine-tune GPT2 for 5 epochs:\r\n",
    "optimizer = AdamW(model.parameters())\r\n",
    "fit(model, optimizer, train_loader, val_loader, epochs=3, device=device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training:   0%|          | 0/268 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Directory already exists ---\n",
      "\n",
      "--- Starting epoch #1 ---\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 268/268 [01:03<00:00,  4.25it/s]\n",
      "Validation: 100%|██████████| 15/15 [00:02<00:00,  6.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Epoch #1 finished --- Training cost: 4.357697346853832 / Validation cost: 3.238239254270281\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training:   0%|          | 1/268 [00:00<00:43,  6.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Epoch #1 Saving complete ! ---\n",
      "\n",
      "--- Starting epoch #2 ---\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 268/268 [01:02<00:00,  4.30it/s]\n",
      "Validation: 100%|██████████| 15/15 [00:02<00:00,  6.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Epoch #2 finished --- Training cost: 2.6955439815111633 / Validation cost: 3.2977525446595264\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training:   0%|          | 0/268 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Epoch #2 Saving complete ! ---\n",
      "\n",
      "--- Starting epoch #3 ---\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 268/268 [01:01<00:00,  4.33it/s]\n",
      "Validation: 100%|██████████| 15/15 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Epoch #3 finished --- Training cost: 2.0005977358582085 / Validation cost: 3.5433764998652353\n",
      "\n",
      "--- Epoch #3 Saving complete ! ---\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('AI_exam': conda)"
  },
  "interpreter": {
   "hash": "293ef13038b1144d4811de228cdfb91e615f2f48e1a0c87d3a386cf88ee0761d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}