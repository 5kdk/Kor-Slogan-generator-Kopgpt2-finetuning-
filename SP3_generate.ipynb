{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import PreTrainedTokenizerFast\r\n",
    "from transformers import GPT2LMHeadModel\r\n",
    "\r\n",
    "MODEL_NAME = \"skt/kogpt2-base-v2\"\r\n",
    "MODEL_PATH = \"./models/\"\r\n",
    "SEQ_LEN = 50\r\n",
    "TOKENS_DICT = {\r\n",
    "    'bos_token':'</s>',\r\n",
    "    'eos_token':'</s>',\r\n",
    "    'unk_token':'<unk>',\r\n",
    "    'pad_token':'<pad>',\r\n",
    "    'mask_token':'<mask>',\r\n",
    "    'additional_special_tokens':['<context>', '<slogan>'],\r\n",
    "}\r\n",
    "\r\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)\r\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\r\n",
    "tokenizer.add_special_tokens(TOKENS_DICT)\r\n",
    "model.resize_token_embeddings(len(tokenizer))\r\n",
    "\r\n",
    "print(tokenizer.special_tokens_map)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': \"['<context>', '<slogan>']\"}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# HuggingFace에서 top k와 top p로 함수 샘플링\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from tqdm import trange\r\n",
    "\r\n",
    "\r\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\r\n",
    "\r\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\r\n",
    "    if top_k > 0:\r\n",
    "        # top-k의 마지막 토큰보다 확률이 낮은 모든 토큰을 제거\r\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\r\n",
    "        logits[indices_to_remove] = filter_value\r\n",
    "\r\n",
    "    if top_p > 0.0:\r\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\r\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\r\n",
    "\r\n",
    "        # 임계값 이상의 누적 확률을 가진 토큰 제거\r\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\r\n",
    "        \r\n",
    "        # 첫 번째 토큰도 임계값보다 높게 유지하려면 인덱스를 오른쪽으로 이동\r\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\r\n",
    "        sorted_indices_to_remove[..., 0] = 0\r\n",
    "\r\n",
    "        # 정렬된 텐서를 원래 인덱싱에 분산\r\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\r\n",
    "        logits[indices_to_remove] = filter_value\r\n",
    "    return logits\r\n",
    "\r\n",
    "\r\n",
    "# HuggingFace에서 컨텍스트/슬로건 분리 작업에 맞게 조정됨\r\n",
    "def sample_sequence(model, length, context, segments_tokens=None, num_samples=1, temperature=1, top_k=0, top_p=0.0, repetition_penalty=1.0,\r\n",
    "                    device='cpu'):\r\n",
    "    context = torch.tensor(context, dtype=torch.long, device=device)\r\n",
    "    context = context.unsqueeze(0).repeat(num_samples, 1)\r\n",
    "    generated = context\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for _ in trange(length):\r\n",
    "\r\n",
    "            inputs = {'input_ids': generated}\r\n",
    "            if segments_tokens != None:\r\n",
    "              inputs['token_type_ids'] = torch.tensor(segments_tokens[:generated.shape[1]]).unsqueeze(0).repeat(num_samples, 1)\r\n",
    "\r\n",
    "\r\n",
    "            outputs = model(**inputs)  # 참고: GPT-2/Transfo-XL/XLNet/CTRL(캐시된 숨겨진 상태)과 함께 '과거'를 사용할 수도 있음\r\n",
    "            next_token_logits = outputs[0][:, -1, :] / (temperature if temperature > 0 else 1.)\r\n",
    "\r\n",
    "            # CTRL의 반복 페널티(https://arxiv.org/abs/1909.05858)\r\n",
    "            for i in range(num_samples):\r\n",
    "                for _ in set(generated[i].tolist()):\r\n",
    "                    next_token_logits[i, _] /= repetition_penalty\r\n",
    "                \r\n",
    "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\r\n",
    "            if temperature == 0: # greedy sampling:\r\n",
    "                next_token = torch.argmax(filtered_logits, dim=-1).unsqueeze(-1)\r\n",
    "            else:\r\n",
    "                next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\r\n",
    "            generated = torch.cat((generated, next_token), dim=1)\r\n",
    "    return generated\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "context = \"내일금융, 청년들을 위한 신용카드\"\r\n",
    "\r\n",
    "context_tkn = tokenizer.additional_special_tokens_ids[0]\r\n",
    "slogan_tkn = tokenizer.additional_special_tokens_ids[1]\r\n",
    "\r\n",
    "input_ids = [context_tkn] + tokenizer.encode(context)\r\n",
    "\r\n",
    "segments = [slogan_tkn] * SEQ_LEN\r\n",
    "segments[:len(input_ids)] = [context_tkn] * len(input_ids)\r\n",
    "\r\n",
    "input_ids += [slogan_tkn]\r\n",
    "# input_ids = input_ids + [slogan_tkn]\r\n",
    "\r\n",
    "epochs = [5, 10, 15, 20]\r\n",
    "for epoch in epochs:\r\n",
    "  model.load_state_dict(torch.load(MODEL_PATH+f'{epoch}epoch_model_weights.pth'))\r\n",
    "  model.eval()\r\n",
    "\r\n",
    "  # Generate 20 samples of max length 20\r\n",
    "  generated = sample_sequence(model, length=20, context=input_ids, segments_tokens=segments, num_samples=20)\r\n",
    "\r\n",
    "  print('\\n\\n--- Generated Slogans ---\\n')\r\n",
    "\r\n",
    "  for g in generated:\r\n",
    "    slogan = tokenizer.decode(g.squeeze().tolist())\r\n",
    "    slogan = slogan.split('</s>')[0].split('<slogan>')[1]\r\n",
    "    print(slogan)  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 의아서 지구를 타고없는 눈은 집이 배부는 아니 \n",
      " 경모, 믿고 쑥! \n",
      " 틀겐, 전에 내일러물라 \n",
      " 볼 때, 함께 아니다, 특별한 모든 나라 \n",
      "_트 끝 나는 받는 때 세상을_까 \n",
      " 담으면 있다면, 결혼 인긴니까 탐험착! \n",
      " 손금 \n",
      " 나나비수, 내 인 밖에는 전망면으로 작동한 곳 \n",
      " 제구를 준비되는 카페 \n",
      " 소리 그겨울 건 전입해도 일 몸이 안기는 그랜있게 \n",
      " 물은 등급내고 수 없죠 \n",
      " 힘쓰고 없는 \n",
      " 갱봅니다, 영혼에서 치킨은, 시대를 되다 \n",
      " 알 수 없는 나라 햄 \n",
      " 여행상을 아니니다 \n",
      " 맞 숲에서 묻지요 \n",
      " 아답게 6년가로 \n",
      " 인생사로 만나고 반드시! \n",
      " 진정한 일을 위한 새로운 게 존재할주셔 있습니다 \n",
      " 현재날?, 상식을 맞춘 시간이 있다 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 그 날, 기쁨, 화약이 하니까 \n",
      " 함께볼 씹어지기 인생링하는 쓰세요 \n",
      " 꿈여행, 국가대표, 이야기 \n",
      " 가장 이미 당신의 미래를 크기입니다 \n",
      " 이너가 어디에 편해서 아니다? 디지털에 열린다 \n",
      " 디저격 다르게, 직옥콤함을 허물다 \n",
      " 대한민국에 함께 벼슬이 많아 되고율? \n",
      " 오늘은 응 원유로 \n",
      " 집 구할수록 행복다 \n",
      " 지켜주고 싶은 혈관 돌려주고, 영화되지말고 \n",
      " 좋은 010은 무료등을 넘어을 삽니다 \n",
      " 모두가 이상 1동자 위의고, 맞감? \n",
      " 바로, 모두의 힘 \n",
      " 지금 가장 치명적인, 전상,닝 \n",
      " 준비하는 커피 \n",
      " 좋은 보험을 내 마음껏 하다 \n",
      " 굿맨만의맘 앞에 몰아파에다 \n",
      " 실산, 땅이 결국, 온다 \n",
      " 할 것은 내가겐날 \n",
      " 내일의 즐거움이 혁신하는 시간 한마리를 있다 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 답의 끝 다 네라 \n",
      " 민 보고날? \n",
      " 우리아이 첫 첫맘대로 시작된다 \n",
      " 한 아이가생활의 시작 \n",
      " 새로운 기회 \n",
      " 가장 나다운 이이, 이렇게 나나 길 라니다 \n",
      " 올봄, 역시, 쉽게 뜨직감 \n",
      " 올겨울보다 믿음톡 \n",
      " 부딪 옴니다 \n",
      " 반반인 부담이잖아라 \n",
      " 크리스 나도신이 있는 나, 네이디하는 방식 \n",
      " 다시 북방의 나를 \n",
      " 대한민국 행복생활 \n",
      " 다 힘을 믿니다 \n",
      " 모두가 꿈꾸네 \n",
      " 주문해도 지금거데이 어만 허락하세요 \n",
      " 초록산업의 미래를 찾니다 \n",
      " 대한민국 전통시장 \n",
      " 건조한 가장 지적인 위하여 \n",
      " 청년이 열을 명 한 길다 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:18<00:00,  1.10it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 세상을 달리는 모든 곳이 아니라 가족과 가까워지 \n",
      " 사람을 위한 이 쇼핑 \n",
      " 세상의 모든 책, 그비는저 \n",
      " 모두에게 가는 곳이 아니라 아니라 보는 예술이야 \n",
      " 이제 디드한 어버버 브랜드 될 수 있는 혜택몰할다 \n",
      " 나다는 말로구, 챗 \n",
      " 나의 나를 위한 내일로 인생을대전 \n",
      " 내 삶의 태양이 더 부드러<unk>시키는 갑니다 \n",
      " 중소기업이 아트다 \n",
      " 아이에게 맴버가 내 운명을 아우! \n",
      " 너랑, 우리에겐를 다르게 \n",
      " 가는 게 아니라갑다 \n",
      " 겨울이 해열 말이 될수록 방이 있습니다 \n",
      " 청년을 최고가그룹은 \n",
      " 모두에게 추억이 내게도 드라마를 만나다 \n",
      " 한 번을 더하다 \n",
      " 사람을 위한 카드의 행복 \n",
      " 다 함께라면 한 사람의 모든 여행 \n",
      " 행복은 \n",
      " 직관적 금융 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "context = \"신한카드, 청년들을 위한 신용카드\"\r\n",
    "\r\n",
    "context_tkn = tokenizer.additional_special_tokens_ids[0]\r\n",
    "slogan_tkn = tokenizer.additional_special_tokens_ids[1]\r\n",
    "\r\n",
    "input_ids = [context_tkn] + tokenizer.encode(context)\r\n",
    "\r\n",
    "segments = [slogan_tkn] * SEQ_LEN\r\n",
    "segments[:len(input_ids)] = [context_tkn] * len(input_ids)\r\n",
    "\r\n",
    "input_ids += [slogan_tkn]\r\n",
    "\r\n",
    "\r\n",
    "epochs = [5, 10, 15, 20]\r\n",
    "for epoch in epochs:\r\n",
    "  model.load_state_dict(torch.load(MODEL_PATH+f'{epoch}epoch_model_weights.pth'))\r\n",
    "  model.eval()\r\n",
    "\r\n",
    "  # Generate 20 samples of max length 20\r\n",
    "  generated = sample_sequence(model, length=20, context=input_ids, segments_tokens=segments, num_samples=20)\r\n",
    "\r\n",
    "  print('\\n\\n--- Generated Slogans ---\\n')\r\n",
    "\r\n",
    "  for g in generated:\r\n",
    "    slogan = tokenizer.decode(g.squeeze().tolist())\r\n",
    "    slogan = slogan.split('</s>')[0].split('<slogan>')[1]\r\n",
    "    print(slogan)  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:17<00:00,  1.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 모두의 꿈을 준 그리다 \n",
      " 다시. 행복한 나를 위한 올림픽이 무한입니다 \n",
      " 이럼을기술 \n",
      " 밥 놀랄 대한민국 \n",
      " 당 가능성이 이길 되는 사람들의 곳으로 \n",
      " 마셔독한 카말시면 20리고머! 늘어뻑생하세요 \n",
      " 오먼세 가지고 우리사이자 \n",
      " 당신에게 다른어서 이어춰서 무도 휴카프? \n",
      " 덜 수 없는 어린이 더되었죠 \n",
      " 새로움이 일상을 지켜춤 \n",
      " 영심이 적일의 추억입 \n",
      " 편하게 \n",
      " 하나 수 없는 세계그룹,란트 \n",
      " 안에서 사랑하는 대한민국 모든 게 개인 자산템 \n",
      " 기업의 봄, 추입니다!, 따뜻한 선물을 \n",
      " 시대가 하나의 당신에게 \n",
      " 함께 존중없는 꿈도 1등 희망에 \n",
      " 울려 때, 곧 길에 미래을 담다 \n",
      " 완벽한 안에서였야 길로 위해,시간 만들고, 독드 \n",
      " 초등님의 결정을 다르니까 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:17<00:00,  1.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 차라리 마천례수, 학교가 기부례입니다 \n",
      " 자본시장을 멀리기할요!요? \n",
      " 똑똑하게 사는 게 바로, 휴대폰에서! \n",
      " 대한 청춘과 생각위 \n",
      " 관리하세요 \n",
      " 자본시장을 멀립니다 사람 행복을 만들어갑다 \n",
      " 만약로 하는 일자리 \n",
      " 우리는 쓸 수 소비? 우리는 할인? \n",
      " 뻔, 늘 나누는 사람이든해 \n",
      " 눈에, 다가겠습니다 \n",
      " 기업합니다, 스마트 향수 부담 게 곧 자신됩니다 \n",
      " 청년여행, 네아담하면 쉬워 \n",
      " 심는 쇠고기 소비, 즐거운 사람들을 위해 \n",
      " 우리 모두처럼 \n",
      " 지금까지 안전의 전쟁을 아니라 열린까요로 돌아오세요 \n",
      " 신한금융그룹과 함께 \n",
      " 잡끄러자의 자꾸자의 소비세요 \n",
      " 속도를 제주 세상을 부르는 생활 \n",
      " 케이프과틀로 행복하다 \n",
      " 당신의 한 사람을 세정갑니다 사람을 만든 테어로 지금 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:16<00:00,  1.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " 신한금융그룹과 희망을 바꾸는 기업금융그룹 \n",
      " 신한금융그룹과 함께 세상을 키우는 가장 좋은 물 \n",
      " 퍼포털 유아 전통 \n",
      " 신한카드, 금융 \n",
      " 아직 힘이 되어보세요 \n",
      " 디지털로리 악플을 낳금융그룹은 제로로 금융을 만나든다 \n",
      " 신한금융그룹과 함께하는 대한민국을 짓다 \n",
      " 어용은 시작됩니다 \n",
      " 신한금융을 만나다 설 일상을 입다 \n",
      " 투이가드로 당신이 기다리았다는 보험 맴사 있습니다 \n",
      " 즐거움을 지우는 세상 \n",
      " 우리가 기업이다, 대한민국을 당신, 보험의 \n",
      " 신한금융업을 답을 찾다 \n",
      " 신한금융그룹과 함께하는 신한금융그룹 \n",
      " 중소기업을 다다 \n",
      " 금융을 부르는 주문 \n",
      " 소비 주유카드가 다녀 절달팩리일 렌마트 서로의 보험입니다 \n",
      " 신한금융그룹은 척리스트 \n",
      " 내 플레이카 \n",
      " 신한금융그룹은 아름다운 일상을 찾아줍니다 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:16<00:00,  1.22it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      "실을 더하다 \n",
      " 나의 봄이 \n",
      " 나답게 올바르게 씀 \n",
      " 하나처럼 가볍게 일상과 가까워지도록 \n",
      " 금융생활에 다인인 당신도 송석 \n",
      " 나는 움직리스트가다 \n",
      " 올카드엔 심 하겠 꽃하고 받인을 디자인에 퍼펙 해주세요 \n",
      " 신한금융의 기준 \n",
      " 엄마, 그 정성으로 쇼핑으로 벗어나 시작 \n",
      " 카드, 생활의 사람상을 돌려받는 거서다 \n",
      " 금융의 해외주식 하겠습니다 \n",
      " 그 사람생활이 시작됩워진다 \n",
      " 부른들의 일상을 모험다 \n",
      " 여행, 그다., 그 곳 \n",
      " 마다. 카드하이드로 생활을 당신의 성공을 찾아준다 \n",
      " 지금 같이 \n",
      " 금융트업의 스페셜리스트로 따져보면있다 \n",
      " 스타 년 알라 \n",
      "실을 넘어선 쇼핑 있게 \n",
      " 다시, 집이, 계곡집배입니다 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('AI_exam': conda)"
  },
  "interpreter": {
   "hash": "293ef13038b1144d4811de228cdfb91e615f2f48e1a0c87d3a386cf88ee0761d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}