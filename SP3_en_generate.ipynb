{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\r\n",
    "\r\n",
    "MODEL_NAME = 'distilgpt2' #'gpt2-medium'\r\n",
    "MODEL_PATH = \"./models\"\r\n",
    "SEQ_LEN = 50\r\n",
    "\r\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\r\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Declare special tokens for padding and separating the context from the slogan:\r\n",
    "SPECIAL_TOKENS_DICT = {\r\n",
    "    'pad_token': '<pad>',\r\n",
    "    'additional_special_tokens': ['<context>', '<slogan>'],\r\n",
    "}\r\n",
    "\r\n",
    "# 어휘에 다음 특수 토큰을 추가하고 모델의 임베딩 크기를 조정:\r\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS_DICT)\r\n",
    "model.resize_token_embeddings(len(tokenizer))\r\n",
    "\r\n",
    "print(tokenizer.special_tokens_map)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<context>', '<slogan>']\"}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from tqdm import trange\r\n",
    "\r\n",
    "\r\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\r\n",
    "\r\n",
    "    top_k = min(top_k, logits.size(-1))\r\n",
    "    if top_k > 0:\r\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\r\n",
    "        logits[indices_to_remove] = filter_value\r\n",
    "\r\n",
    "    if top_p > 0.0:\r\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\r\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\r\n",
    "\r\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\r\n",
    "        \r\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\r\n",
    "        sorted_indices_to_remove[..., 0] = 0\r\n",
    "\r\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\r\n",
    "        logits[indices_to_remove] = filter_value\r\n",
    "    return logits\r\n",
    "\r\n",
    "\r\n",
    "def sample_sequence(model, length, context, segments_tokens=None, num_samples=1, temperature=1, top_k=0, top_p=0.0, repetition_penalty=1.0,\r\n",
    "                    device='cpu'):\r\n",
    "    context = torch.tensor(context, dtype=torch.long, device=device)\r\n",
    "    context = context.unsqueeze(0).repeat(num_samples, 1)\r\n",
    "    generated = context\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for _ in trange(length):\r\n",
    "\r\n",
    "            inputs = {'input_ids': generated}\r\n",
    "            if segments_tokens != None:\r\n",
    "              inputs['token_type_ids'] = torch.tensor(segments_tokens[:generated.shape[1]]).unsqueeze(0).repeat(num_samples, 1)\r\n",
    "\r\n",
    "\r\n",
    "            outputs = model(**inputs)\r\n",
    "            next_token_logits = outputs[0][:, -1, :] / (temperature if temperature > 0 else 1.)\r\n",
    "\r\n",
    "            for i in range(num_samples):\r\n",
    "                for _ in set(generated[i].tolist()):\r\n",
    "                    next_token_logits[i, _] /= repetition_penalty\r\n",
    "                \r\n",
    "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\r\n",
    "            if temperature == 0:\r\n",
    "                next_token = torch.argmax(filtered_logits, dim=-1).unsqueeze(-1)\r\n",
    "            else:\r\n",
    "                next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\r\n",
    "            generated = torch.cat((generated, next_token), dim=1)\r\n",
    "    return generated\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import json\r\n",
    "import urllib.request\r\n",
    "\r\n",
    "def translate(user_text):\r\n",
    "    input_text = user_text\r\n",
    "\r\n",
    "    client_id = \"\" # 개발자센터에서 발급받은 Client ID 값\r\n",
    "    client_secret = \"\" # 개발자센터에서 발급받은 Client Secret 값\r\n",
    "    encText = urllib.parse.quote(input_text)\r\n",
    "    data = \"source=ko&target=en&text=\" + encText\r\n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\r\n",
    "    request = urllib.request.Request(url)\r\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\r\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\r\n",
    "    response = urllib.request.urlopen(request, data=data.encode(\"utf-8\"))\r\n",
    "    rescode = response.getcode()\r\n",
    "    if(rescode==200):\r\n",
    "        response_body = response.read()\r\n",
    "        res = json.loads(response_body.decode('utf-8'))\r\n",
    "        result = res['message']['result']['translatedText']\r\n",
    "\r\n",
    "    else:\r\n",
    "        print(\"Error Code:\" + rescode)\r\n",
    "        \r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "user_input = ''\r\n",
    "result = translate(user_input)\r\n",
    "\r\n",
    "    \r\n",
    "context_tkn = tokenizer.additional_special_tokens_ids[0]\r\n",
    "slogan_tkn = tokenizer.additional_special_tokens_ids[1]\r\n",
    "\r\n",
    "input_ids = [context_tkn] + tokenizer.encode(result)\r\n",
    "\r\n",
    "segments = [slogan_tkn] * SEQ_LEN\r\n",
    "segments[:len(input_ids)] = [context_tkn] * len(input_ids)\r\n",
    "\r\n",
    "input_ids += [slogan_tkn]\r\n",
    "\r\n",
    "\r\n",
    "model.load_state_dict(torch.load(MODEL_PATH+ '/' + f'en slogan_2epoch_model.pth'))\r\n",
    "model.eval()\r\n",
    "\r\n",
    "\r\n",
    "generated = sample_sequence(model, length=30, context=input_ids, segments_tokens=segments, temperature=0.9, top_k=50, top_p=0.95, num_samples=20)\r\n",
    "\r\n",
    "print('\\n\\n--- Generated Slogans ---\\n')\r\n",
    "\r\n",
    "for g in generated:\r\n",
    "  slogan = tokenizer.decode(g.squeeze().tolist())\r\n",
    "  slogan = slogan.split('<|endoftext|>')[0].split('<slogan>')[1]\r\n",
    "  print(slogan)   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " A coffee company. A great place to have a great coffee.\n",
      " A cup of coffee.\n",
      " A coffee made better.\n",
      " A little cup of a tea.\n",
      " The one who loves coffee.\n",
      " A cup of coffee.\n",
      " A coffee company with an atmosphere.\n",
      " A coffee company. A place for coffee.\n",
      " Coffee as your cup.\n",
      " It won't happen to the coffee.\n",
      " A cup of great coffee.\n",
      " The best coffee company.\n",
      " A fresh cup of coffee.\n",
      " Delivering the best in your coffee.\n",
      " A great way to get your coffee.\n",
      " A cup of coffee.\n",
      " A cup of coffee, but not a cup.\n",
      " A better coffee for the everyday everyday.\n",
      " Have coffee and some coffee.\n",
      " A great place to live!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " We taste the best in the world.\n",
      " Make a cup of coffee for your life.\n",
      " Sake time for coffee.\n",
      " For coffee lovers who want to be Coffee lovers.\n",
      " Making coffee good.\n",
      " All cup. All cup. All flavor.\n",
      " For people who make coffee.\n",
      " The coffee people.\n",
      " Pure coffee. Pure taste.\n",
      " A taste of life.\n",
      " B cup. It's all in good taste.\n",
      " Great coffee can't help you.\n",
      " A good coffee can do!\n",
      " It's what you love.\n",
      " Be proud.\n",
      " All the good things brewing.\n",
      " A little taste of good coffee.\n",
      " For people who know coffee.\n",
      " For coffee lovers. For those who know coffee, they know coffee.\n",
      " It's all in the coffee.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.79it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " A cup of good coffee.\n",
      " A cup of milk in a good book.\n",
      " Make a difference.\n",
      " A good cup of coffee.\n",
      " A cup of good coffee.\n",
      " A good coffee break should be a good time.\n",
      " A coffee drink should be a matter of coffee.\n",
      " A cup of good coffee.\n",
      " The coffee drinker's choice.\n",
      " A cup of the good life.\n",
      " A cup of good and well done.\n",
      " Be yourself. Be yourself.\n",
      " A coffee experience.\n",
      " A cup to yourself.\n",
      " A coffee in the neighborhood with a view.\n",
      " Coffee that's worth talking.\n",
      " A coffee break away.\n",
      " A brand new you.\n",
      " A cup of freshness in the middle.\n",
      " A coffee cup of character.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "    \r\n",
    "context_tkn = tokenizer.additional_special_tokens_ids[0]\r\n",
    "slogan_tkn = tokenizer.additional_special_tokens_ids[1]\r\n",
    "\r\n",
    "input_ids = [context_tkn] + tokenizer.encode(result)\r\n",
    "\r\n",
    "segments = [slogan_tkn] * SEQ_LEN\r\n",
    "segments[:len(input_ids)] = [context_tkn] * len(input_ids)\r\n",
    "\r\n",
    "input_ids += [slogan_tkn]\r\n",
    "\r\n",
    "\r\n",
    "for epoch in range(1, 4):\r\n",
    "  model.load_state_dict(torch.load(MODEL_PATH+ '/' + f'en slogan_{epoch}epoch_model.pth'))\r\n",
    "  model.eval()\r\n",
    "\r\n",
    "  # 최개길이 20의 20개의 슬로건 샘플\r\n",
    "  # 확률분포를 조금 뾰족하게 하여 확률값이 높은 토큰이 살짝 더 잘나오도록 (temperature=0.9)\r\n",
    "  # top_k 샘플링을 적용하여 확률값이 낮은 토큰들은 후보 단어에서 배제 (top_k=5)\r\n",
    "  generated = sample_sequence(model, length=20, context=input_ids, segments_tokens=segments, num_samples=20)\r\n",
    "\r\n",
    "  print('\\n\\n--- Generated Slogans ---\\n')\r\n",
    "\r\n",
    "  for g in generated:\r\n",
    "    slogan = tokenizer.decode(g.squeeze().tolist())\r\n",
    "    slogan = slogan.split('<|endoftext|>')[0].split('<slogan>')[1]\r\n",
    "    print(slogan)   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " Your coffee tray. Your friendly coffee.\n",
      "  Cold coffee has a good stay.\n",
      " A coffee. A great time.\n",
      " An Bean bean. <context> A better coffee than ever. One drop of beans.\n",
      " Bare to seat young? A way to seat young?\n",
      " The cup of coffee.\n",
      " A planted place for new experiences for some of your coffee and whisky.\n",
      "  averring laughter.\n",
      " A small mug ride away from right Coffee.\n",
      " Because coffee is an everyday way to pampered bean.\n",
      " A smart place to go, a small dark much less accounting.\n",
      " Healthful coffee. Own coffee. Food. Love. Your Cuppa.\n",
      " A better fork fullMoon less longer (too) or a <context> No drinks ( professionalism makes life harder.\n",
      " A coffee company. The coffee store. Every Day.\n",
      " A great coffee and a great coffee.\n",
      " Not too flassiful. A Degree to Open Yours():10 electrodes for you.\n",
      " The first coffee. It goes back to coffee.\n",
      " A look, a taste, a beer, worth.\n",
      " IJeff i Jeffi. Let the experience your cup.\n",
      " A small comfort adventure. features little green tea.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " Get moved. Because I love coffee.\n",
      " Where good things come true.\n",
      " You won't want to.\n",
      " Real coffee. Real coffee.\n",
      " A coffee that never clamsites.\n",
      " Every drop.\n",
      " A good way to go with Begaaa.\n",
      " Keeping coffee counts.\n",
      " Soup for the whole kid.\n",
      " It's just a mug in the mug.\n",
      " Cornish taste classics.\n",
      " A well-crafted coffee experience delivered.\n",
      " Passion for coffee.\n",
      " Is the coffee for you?\n",
      " Have only a word.\n",
      " Take us to the top!\n",
      " It is possible.\n",
      " Be a cup of pure freshness, pure taste life.\n",
      " Share. Share. Share. Share on all.\n",
      " It's very refreshing.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.81it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Generated Slogans ---\n",
      "\n",
      " A coffee can't do this without Italia.\n",
      " When someone's cup, you trust a cup.\n",
      " A small coffee break.\n",
      " A place for tea and people.\n",
      " The bean specialist.\n",
      " Emotional coffee everyday. Daily develop.\n",
      " A cup of Coffee best.\n",
      " A leading coffee company in the business!\n",
      " A good long time, a great coffee break.\n",
      " Old in the future.\n",
      " Style your coffee, meaning your time.\n",
      " A great coffee people.\n",
      " Indulge your cuppa. You get your Bays.\n",
      " Have some good coffee.\n",
      " Trust your coffee.\n",
      " A cup of confection.\n",
      " A cup above the rest.\n",
      " A small company with a big reputation.\n",
      " A coffee in the morning. If only late or early.\n",
      " A cool cup of good health.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('AI_exam': conda)"
  },
  "interpreter": {
   "hash": "293ef13038b1144d4811de228cdfb91e615f2f48e1a0c87d3a386cf88ee0761d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}